{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ecaa2dc",
   "metadata": {},
   "source": [
    "# OCR Agent from scratch:\n",
    "Let's build a custom OCR agent with specific requirements:\n",
    "a.) high privacy (sensitive data processing);\n",
    "b.) ability to find and read random alphanumeric codes (identification) with high precision;\n",
    "c.) ability to learn from human feedback.\n",
    "\n",
    "We won't be using any OCR libraries or services.\n",
    "\n",
    "We extract layout features using `OpenCV` and train our local nearsighted (char-level) agent to identify each patch and traverse the patches properly to aggregate the text and tables data in a meaningful way.\n",
    "Modern laptop should be able to handle this project.\n",
    "\n",
    "Then we explore `LLM` integration strategies.\n",
    "\n",
    "As the example workload we used tax-forms: the problem stated as visual layout understanding enabling high-precision data extraction from the multi-page scanned documents (set of page-images) with high number of different classes to recognize, and sensitive user data which must be properly protected.\n",
    "\n",
    "![Reader-walk record with matplotlib](assets/reader-walk.gif)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7acab034",
   "metadata": {},
   "source": [
    "### Content\n",
    "\n",
    "* [Data](Data-Sources.ipynb)\n",
    "* [Utilities](Data-Processing.ipynb)\n",
    "* Extract layout features and visual tokens\n",
    "    * [Cells and grid-lines (tables)](Data-Extraction-1.ipynb)\n",
    "    * [Text-lines, word-level objects, char-level tokens](Data-Extraction-2.ipynb)\n",
    "* Generate training data\n",
    "    * [Labeling](Data-Extraction-3.ipynb)\n",
    "    * [Pipeline](Data-Pipeline.ipynb)\n",
    "    * [Datasets](Datasets.ipynb)\n",
    "* Model architecture\n",
    "    * [Visual encoder, generative and discriminative heads](Model-Backbone.ipynb)\n",
    "    * [Unsupervised and semi-supervise pretraining](Model-Pretraining.ipynb)\n",
    "    * [Supervised multi-task training](Model-Training.ipynb)\n",
    "* Traversal strategies\n",
    "    * [Layout traversal](Traversal-Layout.ipynb)\n",
    "    * [Text aggregation](Traversal-Text.ipynb)\n",
    "    * [Form extraction and validation](Traversal-Form.ipynb)\n",
    "* Reader Agent\n",
    "    * [Wire language model in](Agent-LM.ipynb)\n",
    "    * [Set RAG utilities](Agent-RAG.ipynb)\n",
    "    * [Define FSM](Agent-FSM.ipynb)\n",
    "    * [Reinforcement learning setup](Agent-RL.ipynb)\n",
    "* [Leverage synthetic training data](Data-Gen.ipynb)\n",
    "* [Optimization for production](Optimization.ipynb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "899b0ceb",
   "metadata": {},
   "source": [
    "### Environment\n",
    "\n",
    "    root/\n",
    "    ├── Dockerfile\n",
    "    ├── requirements.txt\n",
    "    ├── init.cnf               -- example of env-configuration file\n",
    "    ├── ...\n",
    "    │\n",
    "    ├── notebooks/             -- jupyter notebooks server root\n",
    "    │   ├── ...\n",
    "    │   ├── data/\n",
    "    │   │   ├── ...\n",
    "    │   │   ├── forms/         -- original PDF files (multi-page)\n",
    "    │   │   ├── images/        -- images of pages\n",
    "    │   │   ├── content/       -- extracted textual content and layout data\n",
    "    │   │   ├── inputs/        -- extracted form inputs data\n",
    "    │   │   ├── training/      -- extracted labeled samples\n",
    "    │   │   ├── feedback/      -- human labeled samples\n",
    "    │   │   └── ...\n",
    "    │   ├── ...\n",
    "    │   ├── models/            -- trained models\n",
    "    │   ├── output/            -- training outcome: history and plots\n",
    "    │   ├── scripts/           -- local python library\n",
    "    │   ├── runs/              -- tensorboard logs\n",
    "    │   └── ...\n",
    "    │   \n",
    "    └── app/                   -- frontend for human interaction\n",
    "        └── ...    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3ebf122",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.10.13\r\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93f2b497",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Apr  4 21:42:10 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 545.29.06              Driver Version: 545.29.06    CUDA Version: 12.3     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA GeForce GTX 1660 Ti     Off | 00000000:08:00.0  On |                  N/A |\n",
      "| 38%   30C    P8              17W / 120W |    331MiB /  6144MiB |     27%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    0   N/A  N/A       913      G   /usr/lib/xorg/Xorg                           35MiB |\n",
      "|    0   N/A  N/A      1380      G   /usr/lib/xorg/Xorg                          131MiB |\n",
      "|    0   N/A  N/A      1627      G   /usr/bin/gnome-shell                         71MiB |\n",
      "|    0   N/A  N/A     19019      G   ...seed-version=20240404-180059.409000       79MiB |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db583ad5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.9.0\n"
     ]
    }
   ],
   "source": [
    "import cv2; print(cv2. __version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "07aef363",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU\n",
      "2.1.2+cu121\n"
     ]
    }
   ],
   "source": [
    "import torch; print('GPU' if torch.cuda.is_available() else 'CPU'); print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe73b69f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!jupyter nbconvert --to markdown README.ipynb --output ../README.md"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
