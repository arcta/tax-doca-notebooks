{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "49c166cd",
   "metadata": {},
   "source": [
    "# Data extracted from PDF forms\n",
    "For this project we need\n",
    "* `layout`: hierarchy of blocks defined by bounding box coordinates and `type`\n",
    "* `text`: words and `phrases` (linked sequences)\n",
    "* `inputs`: fields where certain data should be entered defined by text `label` and data type spec.\n",
    "* `images`: some are `logos` we want to recognize; some contain text we want to be aware of for our vision model\n",
    "\n",
    "There are several options, we use `PyMuPDF` package: `scripts/parse.py` is initial bulk extraction for exploration.\n",
    "\n",
    "For our doc-indexing pipeline we need a refined version based on the representation model our exploration outputs. We also need to chose embedding models (text and image) for similarity queries.\n",
    "\n",
    "* For the text embeddings we go with a pretrained model, maybe with a minimal tune up.\n",
    "* For the image embedding we are going to train our own model based on either `ResNet` or `ViT` architecture adapted to grayscale.\n",
    "\n",
    "The [single-source-batch data-loaders](#loader) we use to simplify training could make learning very sensitive to data quality: we need a way to classify each source for fitness to be a learning sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a492c4b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import json\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from time import time\n",
    "from pathlib import Path\n",
    "from PIL import Image, ImageOps\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms, models\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import patches, colormaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b1a5a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load local notebook-utils\n",
    "from scripts import simulate as sim\n",
    "from scripts import parse, render\n",
    "from scripts.backbone import Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e6336f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# doc-level lookup table\n",
    "docs = pd.read_csv('./data/forms.csv.gz')\n",
    "docs = docs.loc[docs['lang'].isin(['en','fr','sp'])].fillna('')\n",
    "docs['taxonomy'] = docs.apply(lambda r:f\"{r['type']}{r['sub']}\".strip().upper(), axis=1)\n",
    "\n",
    "# page-level reference (multipage docs)\n",
    "pages = pd.read_csv('./data/page-summary.csv.gz')\n",
    "pages['file'] = pages['source'].apply(lambda x:'-'.join(x.split('-')[:-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae341e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pages.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e34059",
   "metadata": {},
   "outputs": [],
   "source": [
    "BOX = ['top','left','bottom','right']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47f62f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = [str(x).split('/').pop()[:-4] for x in Path(f'./data/images').glob('*.png')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b1f27b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# look into data where the inputs info is available\n",
    "samples = pages.loc[(pages['source'].isin(images))&(~pages['source'].str.startswith('que-')),'source'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "716ec6e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pages[pages['source'].isin(samples)]['word-count'].quantile([0.,.25,.5,.75,1.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "997ec1c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pages['inputs'] = pages.apply(lambda r:r['text-input'] + r['check-box'] + r['radio-button'] \\\n",
    "                                        if r['text-input'] >= 0 else 0, axis=1)\n",
    "pages[pages['source'].isin(samples)]['inputs'].quantile([0.,.25,.5,.75,1.])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a238fde9",
   "metadata": {},
   "source": [
    "<a name=\"loader\"></a>\n",
    "\n",
    "Let's explore the page-view data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a684b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PageViewPortDataset(Dataset):\n",
    "    \"\"\"\n",
    "    use a single document noisy variation for a batch of random view-ports\n",
    "    \"\"\"\n",
    "    def __init__(self, source: str, max_samples: int = 8):\n",
    "        self.max_samples = max_samples\n",
    "        # load source image\n",
    "        view = np.array(ImageOps.grayscale(Image.open(f'./data/images/{source}.png')))\n",
    "        #view = make_noisy_sample(view)\n",
    "        # create renderer\n",
    "        self.view = render.AgentView((255. - view).astype(np.uint8))\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.5), (0.5))])\n",
    "        labels = pages.loc[pages['source'] == source, ['word-count','inputs']].values[0]\n",
    "        self.labels = np.array([labels[0] > 500, labels[1] > 0]).astype(int)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.max_samples\n",
    "    \n",
    "    def random_viewport(self):\n",
    "        # pan: anywhere within the page-view bounding box\n",
    "        center = (np.array(self.view.space.center) * (0.5 + np.random.rand(2))).astype(int)\n",
    "        rotation = np.random.randint(0, 360)\n",
    "        # keep sufficient field in view to hint layout\n",
    "        zoom = np.random.rand() - 3.5\n",
    "        return center, rotation, zoom\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # generate random viewport\n",
    "        center, rotation, zoom = self.random_viewport()\n",
    "        # render corresponding view\n",
    "        X = self.transform(self.view.set_state(center, rotation, zoom).astype(np.float32))\n",
    "        Y = self.labels\n",
    "        return X, Y\n",
    "\n",
    "\n",
    "# show example\n",
    "sample = 'cnd-5000-s5.fr-5' #np.random.choice(samples)\n",
    "loader = DataLoader(PageViewPortDataset(sample, max_samples=1), batch_size=1, shuffle=False)\n",
    "for X, Y in loader:\n",
    "    print(f'source: {sample}\\nbatch:  X:{X.shape}  Y:{Y.shape}')\n",
    "    for i in range(1):\n",
    "        fig, ax = plt.subplots(figsize=(4, 4))\n",
    "        ax.imshow(X[i,:].squeeze(), 'gray')\n",
    "        ax.axis('off')\n",
    "        ax.set_title(list(Y[i,:].numpy()))\n",
    "        plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "463da226",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2008f958",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class PageViewDataset(Dataset):\n",
    "    \"\"\"\n",
    "    render pages top-view\n",
    "    \"\"\"\n",
    "    def __init__(self, samples: list):\n",
    "        self.samples = samples\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.5), (0.5))])\n",
    "        self.labels = pages.loc[pages['source'].isin(samples), ['word-count','inputs']].values\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        source = self.samples[idx]\n",
    "        # load source image\n",
    "        view = np.array(ImageOps.grayscale(Image.open(f'./data/images/{source}.png')))\n",
    "        # renderer full-page view\n",
    "        view = render.AgentView((255. - view).astype(np.uint8)).top()\n",
    "        X = self.transform(view.astype(np.float32))\n",
    "        labels = self.labels[idx,:]\n",
    "        Y = np.array([labels[0] > 700, labels[1] > 0]).astype(int)\n",
    "        return X, Y\n",
    "\n",
    "\n",
    "# show one batch\n",
    "loader = DataLoader(PageViewDataset(samples), batch_size=4, shuffle=False)\n",
    "for X, Y in loader:\n",
    "    print(f'source: {sample}\\nbatch:  X:{X.shape}  Y:{Y.shape}')\n",
    "    for i in range(4):\n",
    "        fig, ax = plt.subplots(figsize=(4, 4))\n",
    "        ax.imshow(X[i,:].squeeze(), 'gray')\n",
    "        ax.axis('off')\n",
    "        ax.set_title(f'{sample}: {list(Y[i,:].numpy())}')\n",
    "        plt.show()\n",
    "    break\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd6730b",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [(0,0), (0,1), (1,0), (1,1)]\n",
    "X, Y = [], []\n",
    "test = np.random.choice(samples, 1024, replace=False)\n",
    "for inputs, labels in DataLoader(PageViewDataset(test), batch_size=8, shuffle=False):\n",
    "    for i in range(8):\n",
    "        X.append(inputs[i,:].squeeze().numpy().flatten())\n",
    "        Y.append(classes.index(tuple(labels[i,:].numpy())))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a84b3549",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = LDA(n_components=2)\n",
    "T = lda.fit_transform(X, Y)\n",
    "\n",
    "centers = np.array([np.median(T[np.where(np.array(Y) == k)], axis=0) for k in range(4)])\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "cmap = colormaps['rainbow']\n",
    "ax.scatter(T[:,0], T[:,1], c=np.array(Y)/(len(classes) - 1), cmap=cmap, s=5, alpha=0.3)\n",
    "for i in range(len(classes)):\n",
    "    ax.scatter(centers[i,0], centers[i,1], color=cmap(i/(len(classes) - 1)),\n",
    "               s=75, marker='*', edgecolor='black', label=classes[i])\n",
    "ax.set_title('LDA separated clusters')\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb53492",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(T, columns=['x1','x2'], index=test)\n",
    "df['label'] = Y\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85dd681c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "sources = [s for s in samples if not s in test]\n",
    "for i, (inputs, labels) in enumerate(DataLoader(PageViewDataset(sources), batch_size=64, shuffle=False)):\n",
    "    X, Y = [],[]\n",
    "    for i in range(inputs.shape[0]):\n",
    "        X.append(inputs[i,:].squeeze().numpy().flatten())\n",
    "        Y.append(classes.index(tuple(labels[i,:].numpy())))\n",
    "    D = pd.DataFrame(lda.transform(X), columns=['x1','x2'],\n",
    "                     index=sources[i * 64 : min((i + 1) * 64, ), len(sources)])\n",
    "    D['label'] = Y\n",
    "    data.append(D)\n",
    "\n",
    "data = pd.concatenate(data).drop_duplicates()\n",
    "len(data) == len(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df6ee24",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "ax.scatter(data.iloc[:,0], data.iloc[:,1], c=data.iloc[:,2]/(len(classes) - 1), cmap=cmap, s=1, alpha=0.3)\n",
    "for i in range(len(classes)):\n",
    "    ax.scatter(centers[i,0], centers[i,1], color=cmap(i/(len(classes) - 1)),\n",
    "               s=100, marker='*', edgecolor='black', label=classes[i])\n",
    "ax.set_title('LDA separated clusters')\n",
    "ax.set_xlim([-20, 20])\n",
    "ax.set_ylim([-20, 20])\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbfa2738",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['label'] = data['label'].apply(lambda x:classes[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcac2e7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "535d3004",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for source in samples:\n",
    "    x = np.array(Image.open(f'data/masks/{source}'))\n",
    "    x = (np.eye(len(ORDER))[x][:,:,1:] > 0).astype(int)\n",
    "    x = np.sum(x, (0, 1))\n",
    "    data.append(list(x/np.sum(x)))\n",
    "    \n",
    "data = np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ac184f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 3, figsize=(10, 3))\n",
    "for i, j, c in [(0, 1, 2), (1, 2, 0), (2, 0, 1)]:\n",
    "    ax[i].scatter(data[:,i], data[:,j], c=data[:,c], cmap='rainbow', s=3, alpha=0.3)\n",
    "    ax[i].set_xlabel(ORDER[i].upper())\n",
    "    ax[i].set_xticks([])\n",
    "    ax[i].set_ylabel(ORDER[j].upper())\n",
    "    ax[i].set_yticks([])\n",
    "    ax[i].set_title(f'Color: {ORDER[c].upper()}', fontsize=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b48c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "norm = StandardScaler().fit(data)\n",
    "pca.fit(norm.transform(data))\n",
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1816b6d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = pca.transform(norm.transform(data))\n",
    "\n",
    "fig, ax = plt.subplots(1, 3, figsize=(10, 3))\n",
    "# top two components colored by feature value\n",
    "for i,j in [[0,1],[1,2],[2,0]]:\n",
    "    ax[i].scatter(Y[:,i], Y[:,j], s=3, alpha=0.1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf154a99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cfde25c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
