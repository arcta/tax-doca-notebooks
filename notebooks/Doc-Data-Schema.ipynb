{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3bae902b",
   "metadata": {},
   "source": [
    "# Form Data-Schema\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0976b7ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import cv2\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from elasticsearch import Elasticsearch\n",
    "from PIL import Image, ImageOps\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import patches\n",
    "from matplotlib import colormaps\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f4d7aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.search import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f2f255f",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = pd.read_csv('./data/forms.csv.gz')\n",
    "taxonomy = docs.fillna('').apply(lambda r:f\"{r['type']}{r['sub']}\", axis=1).to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad7d2686",
   "metadata": {},
   "outputs": [],
   "source": [
    "pages = pd.read_csv('./data/pages.csv.gz')\n",
    "median = pages.median(numeric_only=True)\n",
    "DW, DH, DS = np.round(median.loc[['word-width','word-height','space']], 4)\n",
    "DW, DH, DS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c13e03db",
   "metadata": {},
   "outputs": [],
   "source": [
    "BOX = ['left','top','right','bottom']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1afa6dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "eclient = Elasticsearch(\n",
    "    hosts=[os.environ['ELASTIC_URI']],\n",
    "    basic_auth=('elastic', os.environ['ELASTIC_PASSWORD']),\n",
    "    verify_certs=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d5137f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#eclient.search(index=INDEX, query={'match_all': {}})['hits']['hits']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "940e24f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_docs(taxonomy):\n",
    "    \"\"\"\n",
    "    retrieve all docs of the type\n",
    "    \"\"\"\n",
    "    query = {'bool': {'must': [{'match': {'taxonomy_id': taxonomy}}, {'match': {'block_type': 'input'}}]}}\n",
    "    aggs = {'docs': {'terms': {'field': 'doc_id'}}}\n",
    "    return eclient.search(index=INDEX, query=query, aggs=aggs)['aggregations']['docs']['buckets']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ecb282c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_docs(taxonomy):\n",
    "    query = {'bool': {'must': [{'match': {'taxonomy_id': taxonomy}}, {'match': {'block_type': 'input'}}]}}\n",
    "    aggs = {'docs': {'terms': {'field': 'doc_id'}}}\n",
    "    return eclient.search(index=INDEX, query=query, aggs=aggs)['aggregations']['docs']['buckets']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46aafa24",
   "metadata": {},
   "outputs": [],
   "source": [
    "tx = np.random.choice(taxonomy)\n",
    "tx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e75e69e",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = get_docs(tx)\n",
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30172061",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_inputs(doc, input_type=None, size=100):\n",
    "    must = [{'match': {'doc_id': doc}}, {'match': {'block_type': 'input'}}]\n",
    "    if input_type is not None:\n",
    "        must.append({'match_phrase': {'content': {'query': input_type, 'slop': 5 }}})\n",
    "    query = {'bool': {'must': must }}\n",
    "    sort = [{'page_id': {'order': 'asc'}}, {'top': {'order': 'asc'}}, {'left': {'order': 'asc'}}]\n",
    "    return [x['_source'] for x in eclient.search(index=INDEX, query=query, sort=sort, size=size)['hits']['hits']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e03f9f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = np.random.choice([d['key'] for d in docs])\n",
    "print(doc)\n",
    "inputs = find_inputs(doc, size=100)\n",
    "for hit in inputs:\n",
    "    print(f\"Page: {hit['page_id']:<3} {hit['content']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e0992b",
   "metadata": {},
   "outputs": [],
   "source": [
    "page = np.random.choice([hit['page_id'] for hit in inputs])\n",
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf7148b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_page_content(doc, page, size=1000):\n",
    "    query = {'bool': {'must': [{'match': {'doc_id': doc }}, {'match': {'page_id': page }}]}}\n",
    "    sort = [{'top': {'order': 'asc'}}, {'left': {'order': 'asc'}}]\n",
    "    return [x['_source'] for x in eclient.search(index=INDEX, query=query, sort=sort, size=size)['hits']['hits']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f845bdc3",
   "metadata": {},
   "source": [
    "    # doc, page = 'irs-fw3', 1\n",
    "    # doc, page = 'irs-f2439', 6\n",
    "    # doc, page = 'que-TP-930-V.en', 2 # nested inputs\n",
    "    # doc, page = 'cnd-l600-a.fr', 1 # input filter example\n",
    "    # doc, page = 'cnd-t2sch125.en', 0 # missing logo at BR corner\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7fbdf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc, page = 'que-TP-930-V.en', 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82594bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_bbox_overlay(source, data, ax):\n",
    "    image = ImageOps.grayscale(Image.open(f'data/images/{source}.png'))\n",
    "    scale = min(image.size)\n",
    "    image = np.array(image)\n",
    "    ax.imshow(image, 'gray')\n",
    "    for d in data:\n",
    "        w, h = (d['right'] - d['left']) * scale, (d['bottom'] - d['top']) * scale\n",
    "        x, y = d['left'] * scale, d['top'] * scale\n",
    "        color = {'input':'red','word':'orange','line':'gold','block':'yellow','image':'cyan'}[d['block_type']]\n",
    "        if d['block_type'] == 'block':\n",
    "            ax.add_patch(patches.Rectangle((x - 5, y - 5), w + 10, h + 10,\n",
    "                                           linewidth=1, edgecolor=color, facecolor='none'))\n",
    "        else:\n",
    "            ax.add_patch(patches.Rectangle((x, y), w, h, linewidth=1, edgecolor=color, facecolor='none'))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e59b481",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_page_content(doc, page, size=10000)\n",
    "fig, ax = plt.subplots(figsize=(11, 11))\n",
    "show_bbox_overlay(f'{doc}-{page}', data, ax)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c648af",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = pd.read_csv(f'./data/inputs/{doc}-{page}.csv.gz')\n",
    "data = get_page_content(doc, page, size=10000)\n",
    "data = pd.DataFrame.from_dict(data)\n",
    "data = data.loc[data['block_type']!='input']\n",
    "image = ImageOps.grayscale(Image.open(f'data/images/{doc}-{page}.png'))\n",
    "scale = min(image.size)\n",
    "image = np.array(image)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(11, 11))\n",
    "ax.imshow(image, 'gray')\n",
    "for d in data.to_dict('records'):\n",
    "    w, h = (d['right'] - d['left']) * scale, (d['bottom'] - d['top']) * scale\n",
    "    x, y = d['left'] * scale, d['top'] * scale\n",
    "    color = {'input':'red','word':'darkorange','line':'gold','block':'yellow','image':'cyan'}[d['block_type']]\n",
    "    if d['block_type'] == 'word':\n",
    "        ax.add_patch(patches.Rectangle((x, y), w, h, linewidth=0, edgecolor='none', facecolor='gold'))        \n",
    "for d in inputs.to_dict('records'):\n",
    "    w, h = (d['right'] - d['left']) * scale, (d['bottom'] - d['top']) * scale\n",
    "    x, y = d['left'] * scale, d['top'] * scale\n",
    "    ax.add_patch(patches.Rectangle((x + 3, y + 3), w - 6, h - 6,\n",
    "                                   linewidth=1, edgecolor='crimson', facecolor='none'))        \n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5793cf80",
   "metadata": {},
   "outputs": [],
   "source": [
    "    print(len(inputs))\n",
    "    inputs = inputs.loc[inputs['field_type_string']!='Button']\n",
    "    hidden = inputs.loc[(inputs['field_type_string']=='Text')&(inputs['right'] - inputs['left'] < DH)]\n",
    "    inputs = inputs.loc[~inputs.index.isin(hidden.index)]\n",
    "    #if len(inputs) == 0:\n",
    "    #    return\n",
    "    print(len(inputs))\n",
    "    # get content from page (already indexed)\n",
    "    #data = get_page_content(doc['file'], inputs.iloc[0]['page'], size=10000)\n",
    "    #if len(data) == 0:\n",
    "    #    return\n",
    "    data = pd.DataFrame.from_dict(data)\n",
    "    print(len(data))\n",
    "    data = data.loc[data['block_type']!='input']\n",
    "    print(len(data))\n",
    "    \n",
    "    #columns = ['content','block_type','left','top','right','bottom']\n",
    "    data = pd.DataFrame.from_dict(data)[['content','block_type'] + BOX]\n",
    "\n",
    "    # build low-res word-presence map to detect overlap easily\n",
    "    M = np.round(data[data['block_type']=='word'].loc[:,BOX] * 100).astype(int)\n",
    "    #if len(M) == 0:\n",
    "    #    return\n",
    "    W, H = M[['right','bottom']].max().astype(int)\n",
    "    matrix = np.zeros((H, W))\n",
    "    for d in M.to_dict('records'):\n",
    "        matrix[int(d['top']) + 1:int(d['bottom']), int(d['left']) + 1:int(d['right'])] = 1\n",
    "    nested = []\n",
    "    test = np.round(inputs.loc[:,BOX] * 100).astype(int)\n",
    "    for i in inputs.index: # if input space is already occupied -- it's nested\n",
    "        l, t, r, b = test.loc[i,:].values\n",
    "        if np.any(matrix[int(t) + 1:int(b), int(l) + 1:int(r)]):\n",
    "            nested.append(i)\n",
    "    # filter-out nested\n",
    "    inputs = inputs.loc[~inputs.index.isin(nested)]\n",
    "    print(len(inputs))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b314d59e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(11, 11))\n",
    "ax.imshow(image, 'gray')\n",
    "for d in data.to_dict('records'):\n",
    "    w, h = (d['right'] - d['left']) * scale, (d['bottom'] - d['top']) * scale\n",
    "    x, y = d['left'] * scale, d['top'] * scale\n",
    "    color = {'input':'red','word':'darkorange','line':'gold','block':'yellow','image':'cyan'}[d['block_type']]\n",
    "    if d['block_type'] == 'word':\n",
    "        ax.add_patch(patches.Rectangle((x, y), w, h, linewidth=0, edgecolor='none', facecolor='orange'))        \n",
    "for d in inputs.to_dict('records'):\n",
    "    w, h = (d['right'] - d['left']) * scale, (d['bottom'] - d['top']) * scale\n",
    "    x, y = d['left'] * scale, d['top'] * scale\n",
    "    ax.add_patch(patches.Rectangle((x + 3, y + 3), w - 6, h - 6,\n",
    "                                   linewidth=1, edgecolor='crimson', facecolor='none'))        \n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f0240c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "810ee03a",
   "metadata": {},
   "source": [
    "Observation: query works but needs correction (may miss some words, especially if the label sits on the right side) -- best strategy depends on the input-type.\n",
    "\n",
    "### Algorithmic approach\n",
    "This based on retrieving the text from the areas which \"look like\" they might be the labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09777585",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_map(data, value, scale=100):\n",
    "    D = data.copy()\n",
    "    D.loc[:,['left','top','right','bottom']] = (D[['left','top','right','bottom']] * scale).astype(int)\n",
    "    #D.loc[:,['left','top']] = (D[['left','top']] * scale).astype(int)\n",
    "    #D.loc[:,['right','bottom']] = np.round(D[['right','bottom']] * scale).astype(int)\n",
    "\n",
    "    w, h = D[['left','top']].min().astype(int)\n",
    "    W, H = D[['right','bottom']].max().astype(int)\n",
    "    matrix = np.zeros((H + h, W + w))\n",
    "    for d in D.to_dict('records'):\n",
    "        matrix[int(d['top']):int(d['bottom']) + 1, int(d['left']):int(d['right']) + 1] = value[d['block_type']]\n",
    "    return matrix[h:,w:], (h, w)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc14bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "todo = pd.read_csv('data/todo.csv.gz')\n",
    "d = np.random.choice(todo[(todo['missing'] > 0)&(todo['missing'] < 1)].to_dict('records'))\n",
    "doc, page = d['file'], int(d['page'])\n",
    "print(d)\n",
    "doc, page = 'que-TP-930-V.en', 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d77669b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_page_content(doc, page)\n",
    "columns = ['content','block_type','left','top','right','bottom']\n",
    "data = pd.DataFrame.from_dict([x['_source'] for x in data]).loc[:,columns]\n",
    "\n",
    "value = {'block':0.33, 'word':0.66, 'input':0.99}\n",
    "matrix, (h, v) = build_map(data, value, scale=100)\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(10,10))\n",
    "show_bbox_overlay(doc, page, data, ax[0])\n",
    "ax[0].set_title('Originall HD image')\n",
    "ax[0].set_axis_off()\n",
    "cmap = colormaps['Oranges']\n",
    "for k,v in value.items(): ax[1].scatter([-10], [10], color=cmap(v), marker='s', s=30, label=k)\n",
    "ax[1].imshow(matrix, 'Oranges')\n",
    "ax[1].set_title('Matrix: low-res. map')\n",
    "ax[1].legend(bbox_to_anchor=(1.3, 1), frameon=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0102addd",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def get_sequence(words, h, w):\n",
    "        # locate the word which satisfies condition\n",
    "        start = words.loc[(words['top'] <= h)&(words['bottom'] >= h)&(words['left'] <= w)&(words['right'] >= w)]\n",
    "        if len(start) == 0:\n",
    "            return\n",
    "        # make sure words are in the proper order\n",
    "        words = words.sort_values(['top','left'])\n",
    "        # get line and in-line position\n",
    "        i, d = start.index[0], start.to_dict('records')[0]\n",
    "        line = words[words['top'] == d['top']].index\n",
    "        # follow the side-wise along the line while linked (one space apart)\n",
    "        left, head = start['left'], []\n",
    "        for x in range(line.get_loc(i) - 1, -1, -1):\n",
    "            if words.loc[line[x], 'right'] > left:\n",
    "                break\n",
    "            left = words.loc[line[x], 'left']\n",
    "            tail.append(words.loc[line[x], 'content'])\n",
    "        right, tail = start['right'], []\n",
    "        for x in range(line.get_loc(i) + 1, len(line)):\n",
    "            if words.loc[line[x], 'left'] > right:\n",
    "                break\n",
    "            right = words.loc[line[x], 'right']\n",
    "            tail.append(words.loc[line[x], 'content'])\n",
    "        # connected sequence\n",
    "        return ' '.join(head + [d['content']] + tail)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "538ee1a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_inputs(data):\n",
    "    inputs = data.loc[data['block_type']=='input']\n",
    "    words = data.loc[data['block_type']=='word'].sort_values(['top','left'])\n",
    "    if len(inputs) == 0:\n",
    "        return\n",
    "    inputs['type'] = inputs['content'].apply(lambda x:x.split(' NAME: ')[0])\n",
    "    inputs['name'] = None\n",
    "    inputs['label'] = None\n",
    "    for i in inputs.index:\n",
    "        d = inputs.loc[i].to_dict()\n",
    "        # first check if the label is provided\n",
    "        name, label = d['content'].split(' LABEL: ')\n",
    "        _,name = name.split(' NAME: ')\n",
    "        inputs.loc[i,'name'] = name\n",
    "        if label != '' and label != 'nan':\n",
    "            inputs.loc[i,'label'] = label\n",
    "            continue\n",
    "        #test = re.sub('([A-Z][a-z]?)', r' \\1', re.sub('(\\d+)', r' \\1', name.replace('_', ' '))).strip()\n",
    "        #if len(test.split()) > 1:\n",
    "        #    inputs.loc[i,'label'] = test.split('_')[0]\n",
    "        #    continue\n",
    "        #label = search_nearby_content(words, d)\n",
    "    return inputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf0c18c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = check_inputs(data)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d31f8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba760dd3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
